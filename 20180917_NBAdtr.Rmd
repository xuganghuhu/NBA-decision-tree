---
title: "20180917_dtr_JD"
author: "hu"
date: "2018年9月17日"
output: html_document
---

```{r setup, include=FALSE}
#载入分析所需要的包
library(dplyr)
library(devtools)
library(woe)   
library(ROSE)
library(rpart)
library(rpart.plot)
library(ggplot2)
require(caret)
library(pROC)
```

# NBA球员大合同决策树分析

本次分析数据为2016-2017赛季NBA300多为球员的技术统计，联系使用决策树技术对球员合同做分类。  
数据来源：  
感谢简书用户“牧羊的男孩”，地址如下：   
https://pan.baidu.com/s/1VjMGm9uzmeb5lnzPkGpD-Q  
以下为“牧羊的男孩”提供的数据字段解释，非常感谢！   
![](https://upload-images.jianshu.io/upload_images/6857799-e501c762be529100.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/700)

## 数据准备

```{r cars}
dat_nba<-read.csv('nba_2017_nba_players_with_salary.csv')
dat_nba$cut_salary<-ifelse(dat_nba$SALARY_MILLIONS>15,1,0)
dat_nba$cut_salary<-as.factor(dat_nba$cut_salary)
dat_nba<-select(dat_nba,-PLAYER,-SALARY_MILLIONS,-TEAM)
cat('目标变量：\n')
summary(dat_nba$cut_salary)
cat('\n')
names(dat_nba)
```

## 计算IV值
```{r}
#install_github("riv","tomasgreif")
#library(devtools)
#library(woe)          
IV<-iv.mult(dat_nba,"cut_salary",TRUE)   #原理是以Y作为被解释变量，其他作为解释变量，建立决策树模型
iv.plot.summary(IV)
```

## 数据不平衡的处理方法
由于京东平台逾期数据量不充足，数据存在严重的不平衡性，可以考虑下采样或者过采样的方法来补充坏样本数据。
```{r}
#install.packages("ROSE")
#library(ROSE)
# 过采样&下采样
datt1<-dat_nba
table(datt1$cut_salary)
data_balanced_both <- ovun.sample(cut_salary ~ ., data = datt1, method = "both", p=0.5,N=342,seed = 1)$data
table(data_balanced_both$cut_salary)

```

## 开始构建决策树
```{r}
#library(rpart)

#设置随机分配，查分数据为train集和test集#
dat=data_balanced_both
smp_size <- floor(0.6 * nrow(dat))
set.seed(123)
train_ind <- sample(seq_len(nrow(dat)), size = smp_size)
train <- dat[train_ind, ]
test <- dat[-train_ind, ]
dim(train)
dim(test)

fit<-(cut_salary~.)
rtree<-rpart(fit,minsplit=10, cp=0.03,data=train)
printcp(rtree)

#library(rpart.plot) #调出rpart.plot包
rpart.plot(rtree, type=2) 

#检验预测效果#
pre_train<-predict(rtree,type = 'vector') #type = c("vector", "prob", "class", "matrix"),
table(pre_train,train$cut_salary)

#检验test集预测效果#
pre_test<-predict(rtree, newdata = test,type = 'vector')
table(pre_test, test$cut_salary)

#检验整体集预测效果#
pre_dat<-predict(rtree, newdata = datt1,type = 'class')
table(pre_dat, datt1$cut_salary)
```

## 决策树选择的字段分布
```{r}
#dat_jd_clean<-select(datt1,fluctuate_amt_w,punish_normal_amt,loan_cnt,atv,cash,max_active_days)
#summary(dat_jd_clean)
```



## 评价决策树
### KS值
```{r}
result=datt1
result$true_label=result$cut_salary
result$pre_label=predict(rtree, newdata = datt1,type = 'class')
result_pro<-predict(rtree, newdata = datt1,type = 'prob')
result$pre_prob<-result_pro[,2]
#install.packages("gmodels")
TPR <- NULL
FPR <- NULL
for(i in seq(from=1,to=0,by=-0.1)){
  #判为正类实际也为正类
  TP <- sum((result$pre_prob >= i) * (result$true_label == 1)) 
  #判为正类实际为负类
  FP <- sum((result$pre_prob >= i) * (result$true_label == 0))
  #判为负类实际为负类
  TN <- sum((result$pre_prob < i) * (result$true_label == 0)) 
  #判为负类实际为正类
  FN <- sum((result$pre_prob < i) * (result$true_label == 1)) 
  TPR <- c(TPR,TP/(TP+FN))
  FPR <- c(FPR,FP/(FP+TN))
}

max(TPR-FPR)#KS

#library(ggplot2)
ggplot(data=NULL,mapping = aes(x=seq(0,1,0.1),y=TPR))+
  geom_point()+
  geom_smooth(se=FALSE,formula = y ~ splines::ns(x,10), method ='lm')+
  geom_line(mapping = aes(x=seq(0,1,0.1),y=FPR),linetype=6)

```
## 混肴矩阵

```{r}
# 找到KS值对应的切分点：
for (i in seq(0,10,1)){
  print(i)
  print(TPR[i]-FPR[i])
}
## 混肴矩阵
result$pre_to1<-ifelse(result$pre_prob>=0.7,1,0)
#require(caret)
xtab<-table(result$pre_to1,result$true_label)
confusionMatrix(xtab)
```

## ROC曲线及AUC
```{r}
## roc曲线及AUC
#library(pROC)
datt1_pro<-predict(rtree, newdata = datt1,type = 'prob')
datt1$pre_prob<-datt1_pro[,2]
modelroc <- roc(datt1$cut_salary,datt1$pre_prob)
plot(modelroc, print.auc=TRUE, auc.polygon=TRUE, grid=c(0.1, 0.2),
     grid.col=c("green", "red"), max.auc.polygon=TRUE,
     auc.polygon.col="skyblue", print.thres=TRUE)
```

```{r}
#设置随机分配，查分数据为train集和test集#
dat=datt1
smp_size <- floor(0.5 * nrow(dat))
train_ind <- sample(seq_len(nrow(dat)), size = smp_size)
train_2 <- dat[train_ind, ]
test_2 <- dat[-train_ind, ]
dim(train_2)
dim(test_2)

#检验预测效果#
pre_train_2<-predict(rtree,newdata=train_2,type = 'vector')
table(pre_train_2,train_2$cut_salary)

#检验test集预测效果#
pre_test_2<-predict(rtree, newdata = test_2,type = 'vector')

table(pre_test_2, test_2$cut_salary)

pre_train_2p<-predict(rtree,newdata=train_2,type = 'prob')
train_2$pre<-pre_train_2p[,2]
modelroc <- roc(train_2$cut_salary,train_2$pre)
plot(modelroc, print.auc=TRUE, auc.polygon=TRUE, grid=c(0.1, 0.2),
     grid.col=c("green", "red"), max.auc.polygon=TRUE,
     auc.polygon.col="skyblue", print.thres=TRUE)


pre_test_2p<-predict(rtree, newdata = test_2,type = 'prob')
test_2$pre<-pre_test_2p[,2]
modelroc <- roc(test_2$cut_salary,test_2$pre)
plot(modelroc, print.auc=TRUE, auc.polygon=TRUE, grid=c(0.1, 0.2),
     grid.col=c("green", "red"), max.auc.polygon=TRUE,
     auc.polygon.col="skyblue", print.thres=TRUE)
```



